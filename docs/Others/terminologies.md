This page has all terminologies / nominclature / nuance that we use in Data Science lifecycle.

### GIT
- staging branch
- main/master branch
- test branch
- push/pull/merge/
- commit
- checkout
- HEAD

### Environment
- Test environment
- production environment
- staging environment

### CMD
- putty
- power shell
- command prompt

### Project
- SME-Subject matter expertise
- SPOC- Single point of contact
- MVP- Minimum viable product
- UAT- User acceptance testing

### Deployment
- Deploy/Ship
- logging
- monitoring
- metrics
- model explainabillity
- hyper parameter tuning
- data drift
- Concept drift (condition to decide churn, now changed over time)
- model drift
- Reproducebility
- trigger based model retraining
- fixed window size data(from last year to current day)
- dynamic window size(moving average)
- Migrate(from pytorch to pytorch_lightning)
- Integrate(combine all modules)
- feasibility study
- Scoping
- Requirements
- MVP(Minimum viable product)
- UAT(user acceptance testing)
- Business metric(increase in email openings)
- Model metric(classification & regression)

## MODELs:
**Knowledge distillation** involves training a smaller model (student) to mimic the behavior of a larger, pre-trained model (teacher) like BERT. This compact model learns not just the teacherâ€™s predictions but also its confidence and reasoning. This approach is particularly useful when deploying BERT on resource-constrained devices.

- latency
- zero, one, few shot learning
- production environment
- deployment environment
- test/UAT environment
- stateless training (from sebastian raschaka Q&A book)
- statefull training
- data-centric ai(focus on data to improve performance.)
- model-centric ai(focus on model to improve performance.)